[
  {
    "id": 11,
    "title": "Structuring Frontend Logic for Unreliable or Delayed APIs",
    "date": "January 11, 2026",
    "excerpt": "How resilient React frontends handle slow or unreliable APIs: standardize remote-data state, use stale-while-revalidate, make retries deliberate, and design writes to be safe under delay.",
    "category": "State Management & Data Flow",
    "image": "https://picsum.photos/367/197?random=48",
    "link": "/blog/structuring-frontend-logic-for-unreliable-or-delayed-apis",
    "slug": "structuring-frontend-logic-for-unreliable-or-delayed-apis",
    "author": "Senior Engineer",
    "tags": [
      "React",
      "Async",
      "Resilience",
      "Error Handling",
      "Caching",
      "Invalidation",
      "Interview Prep"
    ],
    "content": "<p><strong>Interview question:</strong> \u201cHow do you structure frontend logic when working with unreliable or delayed APIs?\u201d</p>\n<p>When APIs are unreliable or slow, a maintainable frontend treats the network as an uncertain dependency rather than a fast, always-correct source of truth. The practical approach is to standardize request state, design the UI to degrade gracefully, and make user actions safe to retry so the application remains predictable even when the backend is not.</p>\n\n<h2>Why \u201cunreliable API\u201d is an architectural problem</h2>\n<p>In small apps, delayed responses are often handled with a spinner and a toast. In larger apps, that approach breaks down because network uncertainty becomes a constant. Users click twice, navigation changes mid-request, and different parts of the UI can drift out of sync.</p>\n<p>Senior engineers usually respond by introducing structure: consistent state models, consistent caching rules, and explicit UX behavior for partial failure. This prevents every feature from inventing its own error handling strategy.</p>\n\n<div class=\"explanation\">\n  <p><strong>\u201cUnreliable\u201d typically means three things.</strong> Requests can be slow, requests can fail intermittently, and responses can arrive out of order. Each of those failure modes suggests a different mitigation, so it helps to name which one is being addressed.</p>\n  <p><strong>\u201cDelayed\u201d also changes user behavior.</strong> When the UI does not respond quickly, users retry actions, switch screens, or lose trust. The frontend needs patterns that assume those behaviors will happen.</p>\n</div>\n\n<h2>Start by standardizing request and screen state</h2>\n<p>A front end becomes resilient when it uses a small, consistent vocabulary for remote data. If every screen models loading and error differently, users see inconsistent states and engineers repeat the same bugs.</p>\n<p>A common pattern is to represent remote data as a tagged state (idle/loading/success/error) with optional \u201clast known good\u201d data so the UI can keep working during temporary failures.</p>\n\n<div class=\"example\">\n  <p><strong>Example:</strong> a remote data state model that supports \u201cshow last good data\u201d and staleness checks.</p>\n  <pre><code>// A simple request state model (TypeScript-friendly)\ntype RemoteData&lt;T&gt; =\n  | { status: \"idle\" }\n  | { status: \"loading\" }\n  | { status: \"success\"; data: T; fetchedAt: number }\n  | { status: \"error\"; error: string; lastGood?: T; fetchedAt?: number };\n\nfunction isStale(fetchedAt: number, staleAfterMs: number) {\n  return Date.now() - fetchedAt &gt; staleAfterMs;\n}</code></pre>\n</div>\n\n<h2>Prefer stale-while-revalidate over \u201cblank screen until fresh\u201d</h2>\n<p>When an API is slow, the user experience improves dramatically if the UI can show cached or last-known data immediately, then refresh in the background. This avoids the feeling that the app is broken whenever the network is.</p>\n<p>In practice, this means keeping a cache layer (or at least a last-known response) and surfacing freshness honestly. Showing \u201colder data\u201d is better than pretending data is current when it is not.</p>\n\n<div class=\"example\">\n  <p><strong>Example:</strong> a UI that renders last-known orders, allows manual refresh, and signals staleness.</p>\n  <pre><code>function OrdersPanel() {\n  const { data, error, isFetching, refetch, dataUpdatedAt } = useOrdersQuery();\n\n  const stale = dataUpdatedAt ? Date.now() - dataUpdatedAt &gt; 60_000 : false;\n\n  return (\n    &lt;section&gt;\n      &lt;header&gt;\n        &lt;h3&gt;Orders&lt;/h3&gt;\n        &lt;button onClick={() =&gt; refetch()} disabled={isFetching}&gt;\n          Refresh\n        &lt;/button&gt;\n        {stale ? &lt;span aria-live=\"polite\"&gt;Showing older data&lt;/span&gt; : null}\n      &lt;/header&gt;\n\n      {error ? (\n        &lt;div role=\"alert\"&gt;\n          Could not refresh right now. {data ? \"Showing last known results.\" : \"Try again.\"}\n        &lt;/div&gt;\n      ) : null}\n\n      {data ? &lt;OrdersTable orders={data} /&gt; : &lt;SkeletonRows /&gt;}\n    &lt;/section&gt;\n  );\n}</code></pre>\n</div>\n\n<h2>Make network behavior explicit: timeouts, retries, and backoff</h2>\n<p>Without explicit policies, slow APIs create \u201cinfinite loading\u201d states and cascading failures. Teams usually introduce timeouts so the UI can recover, and retries with backoff for transient failures.</p>\n<p><strong>The key is to retry the right things.</strong> Retrying a read request is often safe. Retrying a write request may create duplicates unless the system is designed for it.</p>\n\n<div class=\"example\">\n  <p><strong>Example:</strong> a timeout wrapper and exponential backoff for transient failures.</p>\n  <pre><code>async function fetchWithTimeout(url: string, ms: number, signal?: AbortSignal) {\n  const controller = new AbortController();\n  const timeout = setTimeout(() =&gt; controller.abort(), ms);\n\n  // If an upstream signal is provided, abort this request too\n  const onAbort = () =&gt; controller.abort();\n  signal?.addEventListener(\"abort\", onAbort);\n\n  try {\n    const res = await fetch(url, { signal: controller.signal });\n    if (!res.ok) throw new Error(`HTTP ${res.status}`);\n    return await res.json();\n  } finally {\n    clearTimeout(timeout);\n    signal?.removeEventListener(\"abort\", onAbort);\n  }\n}\n\nasync function fetchWithBackoff&lt;T&gt;(fn: () =&gt; Promise&lt;T&gt;, attempts = 3) {\n  let delay = 250;\n  for (let i = 0; i &lt; attempts; i++) {\n    try {\n      return await fn();\n    } catch (e) {\n      if (i === attempts - 1) throw e;\n      await new Promise((r) =&gt; setTimeout(r, delay));\n      delay *= 2;\n    }\n  }\n  throw new Error(\"unreachable\");\n}</code></pre>\n</div>\n\n<h2>Design user actions to be safe under retries</h2>\n<p>When APIs are delayed, users will retry. The UI should assume duplicate submissions are likely and either prevent them (disable buttons, show pending state) or make them safe (idempotency).</p>\n<p>Idempotency means that repeating the same request does not create repeated side effects. On the frontend, that typically looks like attaching an idempotency key to write operations so server-side handlers can deduplicate.</p>\n\n<div class=\"example\">\n  <p><strong>Example:</strong> using an idempotency key for a create operation so the user can retry safely.</p>\n  <pre><code>// When the API may be delayed, the UI should assume retries may occur.\n// Idempotency keys help prevent duplicate server-side actions.\nasync function createOrder(payload: any) {\n  const idempotencyKey = crypto.randomUUID();\n  const res = await fetch(\"/api/orders\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\", \"Idempotency-Key\": idempotencyKey },\n    body: JSON.stringify(payload),\n  });\n  if (!res.ok) throw new Error(\"Create order failed\");\n  return await res.json();\n}</code></pre>\n</div>\n\n<h2>Handle partial failure with clear UX contracts</h2>\n<p>In unreliable systems, it is common that one panel loads while another fails, or a background refresh fails while cached data exists. A resilient UI treats those as normal states, not exceptional ones.</p>\n<p>Teams often define a small set of UX rules, such as: \u201cIf cached data exists, keep showing it and display a non-blocking error.\u201d If no data exists, show an error state with a retry action. If the user initiated the request, show a direct, contextual failure message.</p>\n\n<h2>Tradeoffs and failure modes</h2>\n<p><strong>Showing last-known data can mislead users if freshness is not communicated.</strong> That is why staleness indicators and timestamps matter in domains like billing, inventory, or dispatch. The UI should not silently mask data quality problems.</p>\n<p><strong>Retries can amplify outages.</strong> Aggressive retry loops can overload already struggling services. Backoff, jitter, and circuit-breaker-like behavior (pause retries after repeated failures) help reduce that risk.</p>\n<p><strong>Complexity can creep into every component.</strong> If each screen implements its own timeout, retry, and stale-data logic, the app becomes inconsistent again. The maintainable move is to centralize these policies in a data layer and expose a small, consistent interface to the UI.</p>\n\n<h2>Conclusion</h2>\n<p>Working with unreliable or delayed APIs is mostly about making uncertainty a first-class concern. Maintainable frontends standardize remote-data state, prefer stale-while-revalidate for responsiveness, define clear timeout and retry policies, and design writes to be safe under retries. When those patterns are consistent, features can remain simple even when the network is not.</p>\n\n<div class=\"takeaway\">\n  <p><strong>Interview-ready answer (example of what a candidate might say out loud):</strong> I assume the network is unreliable and structure the frontend so it stays predictable under delay and failure. I standardize remote-data state, show last-known data with a clear freshness signal, and refresh in the background using a cache layer. For reliability, I use timeouts and limited retries with backoff for reads, and I make writes safe to retry by preventing double-submits and using idempotency keys when possible. I also centralize these policies so each screen doesn\u2019t reinvent error handling.</p>\n</div>"
  }
]